{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-4WHmgjAsoJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "6c26e76b-1a54-4e76-f87f-0c6aa1ae00bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jcopdl==1.1.10\n",
            "  Downloading jcopdl-1.1.10.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from jcopdl==1.1.10) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from jcopdl==1.1.10) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from jcopdl==1.1.10) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from jcopdl==1.1.10) (3.10.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from jcopdl==1.1.10) (11.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->jcopdl==1.1.10) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->jcopdl==1.1.10) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->jcopdl==1.1.10) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->jcopdl==1.1.10) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->jcopdl==1.1.10) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->jcopdl==1.1.10) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->jcopdl==1.1.10) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->jcopdl==1.1.10) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->jcopdl==1.1.10) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->jcopdl==1.1.10) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->jcopdl==1.1.10) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->jcopdl==1.1.10) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->jcopdl==1.1.10) (3.0.2)\n",
            "Building wheels for collected packages: jcopdl\n",
            "  Building wheel for jcopdl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jcopdl: filename=jcopdl-1.1.10-py2.py3-none-any.whl size=17915 sha256=041ffd23749e10399defa2a5017cf3f27cdfdb8cc2ecd6aa0627516efa12509d\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/f2/20/aac0878bab38dc24137a63e0977201d72a5f892039d6b38885\n",
            "Successfully built jcopdl\n",
            "Installing collected packages: jcopdl\n",
            "Successfully installed jcopdl-1.1.10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3537724807.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install jcopdl==1.1.10'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install gdown'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36mprint_previous_import_warning\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;34m\"\"\"Prints a warning about previously imported packages.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# display a list of packages using the colab-display-data mimetype, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_previously_imported_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"List all previously imported packages from a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_toplevel_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstalled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_extract_toplevel_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Extract the list of toplevel packages associated with a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtoplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mtoplevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_inferred\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    957\u001b[0m     opt_names = {\n\u001b[1;32m    958\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodulename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malways_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m     }\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfiles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         return skip_missing_files(\n\u001b[0m\u001b[1;32m    501\u001b[0m             make_files(\n\u001b[1;32m    502\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/_functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(param, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mskip_missing_files\u001b[0;34m(package_paths)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \"\"\"\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ignore_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mstat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mdoes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \"\"\"\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "!pip install jcopdl==1.1.10\n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1WmEmUz6l3jXpV-znFu3EqqjTn4kf2OcJ"
      ],
      "metadata": {
        "id": "c44aOSKyBaoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jcopdl\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n"
      ],
      "metadata": {
        "id": "lF2-jg4QCv53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/sendi-full.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "r3-m2Z0PC6BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/sendi/data /content/\n",
        "!rm -r /content/sendi"
      ],
      "metadata": {
        "id": "tBQhoAlsDCbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from jcopdl.callback import Callback, set_config\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "lGhKRBooJ_XA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset & Dataloader"
      ],
      "metadata": {
        "id": "lNTgdzjiKFHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map5to3 = {0:0, 1:0, 2:0, 3:1, 4:2}"
      ],
      "metadata": {
        "id": "63OuhXArCeih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "bs = 32\n",
        "crop_size = 224\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet standards\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_set = datasets.ImageFolder(\"data/train\", transform=train_transform, target_transform=lambda y: map5to3[y])\n",
        "trainloader = DataLoader(train_set, batch_size=bs, shuffle=True, num_workers=4)\n",
        "\n",
        "val_set = datasets.ImageFolder(\"data/val\", transform=test_transform, target_transform=lambda y: map5to3[y])\n",
        "valloader = DataLoader(val_set, batch_size=bs, shuffle=False, num_workers=4)\n",
        "\n",
        "test_set = datasets.ImageFolder(\"data/test\", transform=test_transform, target_transform=lambda y: map5to3[y])\n",
        "testloader = DataLoader(test_set, batch_size=bs, shuffle=False)\n"
      ],
      "metadata": {
        "id": "wQQDZZ5EKYJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label2cat = [\"class0_1_2\", \"class3\", \"class4\"]\n",
        "label2cat"
      ],
      "metadata": {
        "id": "u5b4RtcVP8BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Arsitektur & Config"
      ],
      "metadata": {
        "id": "EOtyoPTPQKSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet18\n",
        "\n",
        "resnet = resnet18(pretrained=True)\n",
        "\n",
        "for param in resnet.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "f1b4fO2kQGPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_ftrs = resnet.fc.in_features"
      ],
      "metadata": {
        "id": "Fwy-xnh6RaaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet"
      ],
      "metadata": {
        "id": "sS0JydqO45SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomResnet18(nn.Module):\n",
        "    def __init__(self, output_size):\n",
        "        super().__init__()\n",
        "        self.resnet = resnet18(pretrained=True)\n",
        "        self.frezee()\n",
        "        self.resnet.fc = nn.Linear(num_ftrs, output_size)\n",
        "\n",
        "    def frezee(self):\n",
        "        for param in self.resnet.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def unfrezee(self):\n",
        "        for param in self.resnet.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "T76J_RPoUDF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = set_config({\n",
        "    \"output_size\" : len(label2cat),\n",
        "    \"batch_size\" : bs,\n",
        "    \"crop_size\" : crop_size,\n",
        "})"
      ],
      "metadata": {
        "id": "m0mep2xET3lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Phase1 : Adaptation (lr standard + patience kecil)"
      ],
      "metadata": {
        "id": "NWJ0O0VJV5ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomResnet18(config.output_size).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
        "callback = Callback(model, config,early_stop_patience=2, outdir=\"model\")"
      ],
      "metadata": {
        "id": "HMZWXU22WRxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "num_classes = 3\n",
        "counts = Counter(train_set.targets)  # ImageFolder punya .targets\n",
        "w = np.array([counts[c] for c in range(num_classes)], dtype=np.float64)\n",
        "w = w.sum() / (w + 1e-6)\n",
        "w = (w / w.mean()).astype(np.float32)\n",
        "\n",
        "class_weights = torch.tensor(w).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n"
      ],
      "metadata": {
        "id": "IJtn3Zp2fWWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def loop_fn(mode, dataset, dataloader, model, criterion, optimizer, device):\n",
        "    if mode == \"train\":\n",
        "        model.train()\n",
        "    elif mode == \"test\":\n",
        "        model.eval()\n",
        "    cost = correct = 0\n",
        "    for feature, target in tqdm(dataloader, desc=mode.title()):\n",
        "        feature, target = feature.to(device), target.to(device)\n",
        "        output = model(feature)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        if mode == \"train\":\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        cost += loss.item() * feature.shape[0]\n",
        "        correct += (output.argmax(1) == target).sum().item()\n",
        "    cost = cost / len(dataset)\n",
        "    acc = correct / len(dataset)\n",
        "    return cost, acc"
      ],
      "metadata": {
        "id": "kkt8mJySXIme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    train_cost, train_score = loop_fn(\"train\", train_set, trainloader, model, criterion, optimizer, device)\n",
        "    with torch.no_grad():\n",
        "        test_cost, test_score = loop_fn(\"test\", test_set, testloader, model, criterion, optimizer, device)\n",
        "\n",
        "    # Logging\n",
        "    callback.log(train_cost, test_cost, train_score, test_score)\n",
        "\n",
        "    # Checkpoint\n",
        "    callback.save_checkpoint()\n",
        "\n",
        "    # Runtime Plotting\n",
        "    callback.cost_runtime_plotting()\n",
        "    callback.score_runtime_plotting()\n",
        "\n",
        "    # Early Stopping\n",
        "    if callback.early_stopping(model, monitor=\"test_score\"):\n",
        "        callback.plot_cost()\n",
        "        callback.plot_score()\n",
        "        break"
      ],
      "metadata": {
        "id": "pZO4DE_zXKGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Phase 2 : Fine-tuning (lr kecil, patience ditambah)"
      ],
      "metadata": {
        "id": "zk3kO1YlX9SE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.unfrezee()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
        "callback.reset_early_stop()\n",
        "callback.early_stop_patience = 5\n"
      ],
      "metadata": {
        "id": "p0TTKDC6XQSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    train_cost, train_score = loop_fn(\"train\", train_set, trainloader, model, criterion, optimizer, device)\n",
        "    with torch.no_grad():\n",
        "        val_cost,   val_score   = loop_fn(\"test\",  val_set,   valloader,   model, criterion, optimizer, device)\n",
        "\n",
        "    # log & plot (pakai val)\n",
        "    callback.log(train_cost, val_cost, train_score, val_score)\n",
        "    callback.save_checkpoint()\n",
        "    callback.cost_runtime_plotting(); callback.score_runtime_plotting()\n",
        "\n",
        "    if callback.early_stopping(model, monitor=\"test_score\"):  # 'test_score' di callback = kolom ke-4, kita isi val_score\n",
        "        callback.plot_cost(); callback.plot_score()\n",
        "        break"
      ],
      "metadata": {
        "id": "KaeBr-kXdZOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "id": "VVhP6FM8GtMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === EVALUASI (3 kelas) ===\n",
        "model.eval()\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        preds = outputs.argmax(1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class_names = ['Healthy', 'Moderate', 'Severe']\n",
        "\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names, digits=4))\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds, labels=[0, 1, 2])\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1SFjgVPtPW4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature, target = next(iter(testloader))\n",
        "feature, target = feature.to(device), target.to(device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  output = model(feature)\n",
        "  preds = torch.argmax(output, dim=1)\n",
        "\n",
        "print(\"Predicted:\", preds[:10].cpu().numpy())\n",
        "print(\"Ground truth:\", target[:10].cpu().numpy())"
      ],
      "metadata": {
        "id": "jGTsSkzEsV-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sanity Check\n",
        "\n"
      ],
      "metadata": {
        "id": "UFy6Bp5EIKVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_label(x):\n",
        "    return label2cat[int(x)]\n",
        "\n",
        "def inverse_norm(img):\n",
        "  img[0, :, :] = img[0, :, :] * 0.229 + 0.485\n",
        "  img[1, :, :] = img[1, :, :] * 0.224 + 0.456\n",
        "  img[2, :, :] = img[2, :, :] * 0.225 + 0.406\n",
        "  return img"
      ],
      "metadata": {
        "id": "ryF67LiodZJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, numpy as np, matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "\n",
        "# Nama kelas 3-class\n",
        "class_names = ['Healthy', 'Moderate', 'Severe']\n",
        "idx2name = dict(enumerate(class_names))\n",
        "\n",
        "def inverse_norm(img):\n",
        "    img = img.clone()\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
        "    std  = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
        "    img = img * std + mean\n",
        "    return img.clamp(0, 1)\n",
        "\n",
        "# ===== kumpulkan SEMUA gambar + prediksi dari testloader =====\n",
        "model.eval()\n",
        "imgs_all, labels_all, preds_all = [], [], []\n",
        "with torch.no_grad():\n",
        "    for x, y in testloader:\n",
        "        p = model(x.to(device)).argmax(1).cpu()\n",
        "        imgs_all.extend(x.cpu())\n",
        "        labels_all.extend(y.cpu())\n",
        "        preds_all.extend(p)\n",
        "\n",
        "N = len(imgs_all)\n",
        "print(f\"Total test images: {N}\")\n",
        "\n",
        "# ===== buat PDF multi-halaman =====\n",
        "per_page = 36\n",
        "cols = 6\n",
        "rows = (per_page + cols - 1)//cols\n",
        "\n",
        "pdf_path = \"test_predictions.pdf\"\n",
        "with PdfPages(pdf_path) as pdf:\n",
        "    for start in range(0, N, per_page):\n",
        "        end = min(start + per_page, N)\n",
        "        fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))\n",
        "        axes = np.array(axes).reshape(rows, cols)\n",
        "\n",
        "        for i in range(rows*cols):\n",
        "            ax = axes[i // cols, i % cols]\n",
        "            idx = start + i\n",
        "            if idx < end:\n",
        "                img = inverse_norm(imgs_all[idx]).permute(1,2,0).numpy()\n",
        "                y = int(labels_all[idx]); p = int(preds_all[idx])\n",
        "                ax.imshow(img)\n",
        "                ax.set_title(f\"Label: {idx2name[y]}\\nPred: {idx2name[p]}\",\n",
        "                             color=('g' if y==p else 'r'), fontsize=10)\n",
        "                ax.axis('off')\n",
        "            else:\n",
        "                ax.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        pdf.savefig(fig)\n",
        "        plt.close(fig)\n",
        "\n",
        "print(f\"Selesai. File disimpan: {pdf_path}\")\n",
        "\n",
        "# (opsional) tampilkan halaman pertama di notebook\n",
        "from math import ceil\n",
        "first_end = min(per_page, N)\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))\n",
        "axes = np.array(axes).reshape(rows, cols)\n",
        "for i in range(rows*cols):\n",
        "    ax = axes[i // cols, i % cols]\n",
        "    if i < first_end:\n",
        "        img = inverse_norm(imgs_all[i]).permute(1,2,0).numpy()\n",
        "        y = int(labels_all[i]); p = int(preds_all[i])\n",
        "        ax.imshow(img)\n",
        "        ax.set_title(f\"Label: {idx2name[y]}\\nPred: {idx2name[p]}\",\n",
        "                     color=('g' if y==p else 'r'), fontsize=10)\n",
        "        ax.axis('off')\n",
        "    else:\n",
        "        ax.axis('off')\n",
        "plt.tight_layout(); plt.show()\n"
      ],
      "metadata": {
        "id": "n2D8AWtUL3eT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # kalau wrapper-mu menyimpan backbone di atribut .resnet\n",
        "    in_f = model.resnet.fc.in_features\n",
        "    if getattr(model.resnet.fc, 'out_features', None) != 3:\n",
        "        model.resnet.fc = nn.Linear(in_f, 3).to(device)\n",
        "except AttributeError:\n",
        "    # fallback kalau nama atribut berbeda\n",
        "    print(\"Backbone bukan di model.resnet; lihat Cara robust di bawah.\")\n",
        "\n",
        "# 1) fungsi bantu hitung distribusi label dari dataset apapun (ImageFolder / wrapper)\n",
        "from collections import Counter\n",
        "def count_labels(ds):\n",
        "    if hasattr(ds, \"targets\"):  # ImageFolder atau wrapper yg expose .targets\n",
        "        ys = ds.targets\n",
        "    else:\n",
        "        ys = [ds[i][1] for i in range(len(ds))]\n",
        "    return Counter(ys)\n",
        "\n",
        "print(\"Train dist:\", count_labels(train_set))\n",
        "print(\"Val   dist:\", count_labels(val_set))\n",
        "print(\"Test  dist:\", count_labels(test_set))\n"
      ],
      "metadata": {
        "id": "8k6D9rvmL3a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 10 gambar per kelas (total 30), seimbang by TRUE LABEL =====\n",
        "import math, numpy as np\n",
        "\n",
        "class_names = ['Healthy', 'Moderate', 'Severe']\n",
        "idx2name = dict(enumerate(class_names))\n",
        "\n",
        "# 1) Kumpulkan indeks per kelas\n",
        "idx_by_cls = {c: [i for i, y in enumerate(labels_all) if int(y) == c] for c in range(3)}\n",
        "for c in idx_by_cls:\n",
        "    np.random.shuffle(idx_by_cls[c])  # acak biar variatif\n",
        "\n",
        "# 2) Ambil 10 per kelas (atau kurang kalau datanya tidak cukup)\n",
        "k_per_class = min(10, *[len(idx_by_cls[c]) for c in range(3)])\n",
        "balanced_idx = []\n",
        "for i in range(k_per_class):\n",
        "    for c in range(3):  # urutan: 0,1,2,0,1,2,...\n",
        "        balanced_idx.append(idx_by_cls[c][i])\n",
        "\n",
        "print({class_names[c]: len(idx_by_cls[c]) for c in range(3)})\n",
        "print(f\"Menampilkan {k_per_class} per kelas → total {len(balanced_idx)} gambar\")\n",
        "\n",
        "# 3) Plot satu halaman (30 gambar → 6x5)\n",
        "cols = 6\n",
        "rows = math.ceil(len(balanced_idx) / cols)\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))\n",
        "axes = np.array(axes).reshape(rows, cols)\n",
        "\n",
        "for i in range(rows * cols):\n",
        "    ax = axes[i // cols, i % cols]\n",
        "    if i < len(balanced_idx):\n",
        "        idx = balanced_idx[i]\n",
        "        img = inverse_norm(imgs_all[idx]).permute(1, 2, 0).numpy()\n",
        "        y = int(labels_all[idx]); p = int(preds_all[idx])\n",
        "        ax.imshow(img)\n",
        "        ax.set_title(f\"Label: {idx2name[y]}\\nPred: {idx2name[p]}\",\n",
        "                     color=('g' if y == p else 'r'), fontsize=10)\n",
        "        ax.axis('off')\n",
        "    else:\n",
        "        ax.axis('off')\n",
        "\n",
        "fig.suptitle(\"Balanced test predictions (10 per class)\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SXXAxJJKYxSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== SAVE ARTIFACTS ====\n",
        "import torch, json, os\n",
        "from pathlib import Path\n",
        "\n",
        "save_dir = Path(\"export\")\n",
        "save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# pastikan class_names & transform stats sama dgn yang dipakai saat test\n",
        "class_names   = ['Healthy', 'Moderate', 'Severe']\n",
        "imagenet_mean = [0.485, 0.456, 0.406]\n",
        "imagenet_std  = [0.229, 0.224, 0.225]\n",
        "crop_size     = 224   # samakan dgn notebook\n",
        "resize_size   = 256\n",
        "\n",
        "# 1) Simpan state_dict + metadata (format PyTorch)\n",
        "artifact = {\n",
        "    \"arch\": \"resnet18\",\n",
        "    \"state_dict\": (model.resnet.state_dict() if hasattr(model, \"resnet\") else model.state_dict()),\n",
        "    \"class_names\": class_names,\n",
        "    \"mean\": imagenet_mean,\n",
        "    \"std\": imagenet_std,\n",
        "    \"preprocess\": {\"resize\": resize_size, \"center_crop\": crop_size, \"grayscale_to_rgb\": True},\n",
        "}\n",
        "torch.save(artifact, save_dir / \"resnet18_3class_best.pt\")\n",
        "print(\"Saved:\", save_dir / \"resnet18_3class_best.pt\")\n",
        "\n",
        "# 2) (opsional) Simpan TorchScript (portable)\n",
        "model_cpu = (model.resnet if hasattr(model, \"resnet\") else model).cpu().eval()\n",
        "example = torch.randn(1, 3, crop_size, crop_size)\n",
        "traced = torch.jit.trace(model_cpu, example)\n",
        "traced.save(str(save_dir / \"resnet18_3class_traced.pt\"))\n",
        "print(\"Saved:\", save_dir / \"resnet18_3class_traced.pt\")\n",
        "\n",
        "# 3) Simpan class_names & preprocess juga ke JSON (berguna untuk app)\n",
        "with open(save_dir / \"class_names.json\", \"w\") as f:\n",
        "    json.dump(class_names, f)\n",
        "with open(save_dir / \"preprocess.json\", \"w\") as f:\n",
        "    json.dump({\n",
        "        \"resize\": resize_size, \"center_crop\": crop_size,\n",
        "        \"mean\": imagenet_mean, \"std\": imagenet_std,\n",
        "        \"grayscale_to_rgb\": True\n",
        "    }, f, indent=2)\n"
      ],
      "metadata": {
        "id": "9Gh9B8IqKuv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Inference utilities ===\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "def _build_transform_from_meta(meta: dict):\n",
        "    ops = []\n",
        "    if meta[\"preprocess\"].get(\"grayscale_to_rgb\", True):\n",
        "        ops.append(transforms.Grayscale(num_output_channels=3))\n",
        "    if meta[\"preprocess\"].get(\"resize\", None):\n",
        "        ops.append(transforms.Resize(meta[\"preprocess\"][\"resize\"]))\n",
        "    if meta[\"preprocess\"].get(\"center_crop\", None):\n",
        "        ops.append(transforms.CenterCrop(meta[\"preprocess\"][\"center_crop\"]))\n",
        "    ops += [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=meta[\"mean\"], std=meta[\"std\"]),\n",
        "    ]\n",
        "    return transforms.Compose(ops)\n",
        "\n",
        "def load_checkpoint_model(ckpt_path=\"export/resnet18_3class_best.pt\", device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Load checkpoint (.pt / .pth) -> bangun resnet18(num_classes=3) -> load_state_dict\n",
        "    \"\"\"\n",
        "    ckpt = torch.load(ckpt_path, map_location=device)   # <-- torch.load (BUKAN torch.jit.load)\n",
        "    class_names = ckpt[\"class_names\"]\n",
        "    model = resnet18(weights=None, num_classes=len(class_names))\n",
        "    model.load_state_dict(ckpt[\"state_dict\"])\n",
        "    model.eval().to(device)\n",
        "    tfm = _build_transform_from_meta(ckpt)\n",
        "    return model, class_names, tfm\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_path(img_path: str, model, class_names, tfm, device=\"cpu\"):\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    x = tfm(img).unsqueeze(0).to(device)\n",
        "    logits = model(x)\n",
        "    probs = torch.softmax(logits, dim=1).squeeze(0).cpu().tolist()\n",
        "    pred_idx = int(torch.argmax(logits, dim=1).item())\n",
        "    return {\n",
        "        \"pred_idx\": pred_idx,\n",
        "        \"pred_label\": class_names[pred_idx],\n",
        "        \"probs\": {class_names[i]: float(p) for i, p in enumerate(probs)}\n",
        "    }\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_bytes(file_bytes: bytes, model, class_names, tfm, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Berguna untuk FastAPI nanti: terima bytes upload -> prediksi\n",
        "    \"\"\"\n",
        "    img = Image.open(io.BytesIO(file_bytes)).convert(\"RGB\")\n",
        "    x = tfm(img).unsqueeze(0).to(device)\n",
        "    logits = model(x)\n",
        "    probs = torch.softmax(logits, dim=1).squeeze(0).cpu().tolist()\n",
        "    pred_idx = int(torch.argmax(logits, dim=1).item())\n",
        "    return {\n",
        "        \"pred_idx\": pred_idx,\n",
        "        \"pred_label\": class_names[pred_idx],\n",
        "        \"probs\": {class_names[i]: float(p) for i, p in enumerate(probs)}\n",
        "    }\n"
      ],
      "metadata": {
        "id": "CJYIgzgTXkbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Smoke test: load checkpoint & prediksi 1 gambar ===\n",
        "import os, io\n",
        "\n",
        "device = \"cpu\"  # untuk test cepat\n",
        "model_inf, class_names_inf, tfm_inf = load_checkpoint_model(\n",
        "    \"export/resnet18_3class_best.pt\", device=device\n",
        ")\n",
        "print(\"Loaded. Classes:\", class_names_inf)\n",
        "\n",
        "\n",
        "try:\n",
        "    sample_path, _ = test_set.samples[0]\n",
        "except NameError:\n",
        "    sample_path = \"data/test/Healthy/some_image.png\"\n",
        "\n",
        "assert os.path.exists(sample_path), f\"not found: {sample_path}\"\n",
        "\n",
        "res = predict_path(sample_path, model_inf, class_names_inf, tfm_inf, device=device)\n",
        "print(\"Sample prediction:\", res)\n"
      ],
      "metadata": {
        "id": "fpDCoiQsbBPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Full test evaluation from saved artifact ===\n",
        "import torch, json\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import seaborn as sns, matplotlib.pyplot as plt\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# load ulang model & transform dari checkpoint\n",
        "model_eval, class_names_eval, tfm_eval = load_checkpoint_model(\n",
        "    \"export/resnet18_3class_best.pt\", device=device\n",
        ")\n",
        "\n",
        "model_eval.eval()\n",
        "all_labels, all_preds = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in testloader:\n",
        "        xb = xb.to(device)\n",
        "        logits = model_eval(xb)\n",
        "        preds = logits.argmax(1).cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(yb.numpy())\n",
        "\n",
        "acc = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Test accuracy: {acc:.4f}\")\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names_eval))\n",
        "\n",
        "# simpan confusion matrix ke gambar\n",
        "cm = confusion_matrix(all_labels, all_preds, labels=[0,1,2])\n",
        "Path(\"assets\").mkdir(exist_ok=True)\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names_eval, yticklabels=class_names_eval)\n",
        "plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.tight_layout()\n",
        "plt.savefig(\"assets/cm_test.png\", dpi=200)\n",
        "plt.show()\n",
        "\n",
        "# simpan report ke JSON\n",
        "Path(\"export\").mkdir(exist_ok=True)\n",
        "with open(\"export/test_report.json\",\"w\") as f:\n",
        "    json.dump({\n",
        "        \"accuracy\": float(acc),\n",
        "        \"report\": classification_report(all_labels, all_preds, target_names=class_names_eval, output_dict=True)\n",
        "    }, f, indent=2)\n",
        "\n",
        "print(\"Saved -> assets/cm_test.png  &  export/test_report.json\")\n"
      ],
      "metadata": {
        "id": "4TN2p4HXbCyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1uqrtX6QELre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iYhZIXuYELo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bmQ8z-aHELmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9x4XMmbbELkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BeDPGVNOELiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FRLakkQsELgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ue2gcNXmEU9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nNcmj6pTEU4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CpflMcmFEU18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dyefyNk0EUzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QQ1BnB-iEUxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ep3gshkeEUuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tWSjONe9EUpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A6H_H5XEEUkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ixhonjIXELeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QNNZ1c0zELb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h5JTA5DfELZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uc-gZy9sELXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "obO3Wt8ZELVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vnAibnIXELIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#akhir"
      ],
      "metadata": {
        "id": "rhzFM-wXEeI0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lf7TRHtEEdvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8rviepoVEdrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iWE0I31GEdnR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}